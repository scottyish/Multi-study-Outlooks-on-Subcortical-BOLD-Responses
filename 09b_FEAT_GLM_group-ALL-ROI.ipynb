{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207d7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys                               # system functions\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "from nipype.interfaces.io import DataSink\n",
    "import nipype.interfaces.fsl as fsl          # fsl\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "import errno\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from patsy.contrasts import ContrastMatrix\n",
    "import numpy as np\n",
    "\n",
    "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5677ae7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sorted(glob.glob(os.path.join('/home/scotti/projects/3t_7t_sst_comparison', \n",
    "#                              'derivatives', 'glm_feat_sst_roi', 'subject_level_model', '*', 'sub-*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef36b39",
   "metadata": {},
   "source": [
    "### Copes at level 2:\n",
    "##### Model 0:\n",
    "1. FS\n",
    "2. SS\n",
    "3. Go\n",
    "4. FS-Go\n",
    "5. FS-SS\n",
    "6. SS-Go\n",
    "\n",
    "##### Model 1:\n",
    "1. response_left\n",
    "2. response_right\n",
    "3. response_left-response_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b73e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general set-up\n",
    "project_folder = '/home/scotti/projects/3t_7t_sst_comparison'\n",
    "\n",
    "dataset_ids = [x.split('/')[-1]for x in sorted(glob.glob(os.path.join(project_folder, 'derivatives', 'glm_feat_sst_roi', 'subject_level_model/*')))]\n",
    "model_ns = ['0']\n",
    "# fwhms = ['base']\n",
    "\n",
    "if model_ns[0] == '0':\n",
    "    contrasts = ['0','1','2','3','4','5']  # task from second level model\n",
    "elif model_ns[0] == '1':\n",
    "    contrasts = ['0','1','2'] # motor from second level model\n",
    "if model_ns[0] == '2':\n",
    "    contrasts = ['0','1','2','3','4','5']  # task from second level model\n",
    "\n",
    "subject_ids = [x.split('/')[-1].split('-')[-1] for x in sorted(glob.glob(os.path.join(project_folder, 'derivatives', 'glm_feat_sst_roi', \n",
    "                                     'subject_level_model', '*', 'sub-*')))]\n",
    "\n",
    "work_dir = os.path.join(project_folder, 'processing', 'nipype_workflow_folders', 'all_datasets_roi')\n",
    "slm_folder = os.path.join(project_folder, 'derivatives', 'glm_feat_sst_roi', 'subject_level_model')\n",
    "\n",
    "# template_brain = os.path.join(project_folder, 'sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii')\n",
    "# template_brain_mask = os.path.join(project_folder, 'sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain_mask.nii')\n",
    "template_brain_mask = '/home/scotti/projects/3t_7t_sst_comparison/derivatives/mni3mm_brain_mask.nii.gz' #os.path.join(project_folder, 'sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain_mask.nii')\n",
    "\n",
    "output_dir = os.path.join(project_folder, 'derivatives', \"glm_feat_sst_roi\", \"group_level_model\", 'all_datasets', f'model-{model_ns[0]}')\n",
    "\n",
    "templates = {'level2_cope': os.path.join(slm_folder, '*','sub-*', 'func', 'model-{model_n}', '*task-s*_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-cope.nii.gz'),\n",
    "             'level2_varcope': os.path.join(slm_folder, '*','sub-*', 'func', 'model-{model_n}', '*task-s*_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-varcope.nii.gz'),\n",
    "             'level2_tdof': os.path.join(slm_folder, '*','sub-*', 'func', 'model-{model_n}', '*task-s*_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-tdof_t.nii.gz')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aaf4a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datasets : ['Leipzig_7T_GdH', 'Leipzig_7T_SM', 'NTNU_7T_SJSI', 'aron_3T', 'openfmri_3T']\n",
      "model_n : ['0']\n",
      "no. subs : 174\n",
      "subs : ['BI3T', 'FMFT', 'GAIT', 'KCAT', 'KP6T', 'LV2T', 'MRCT', 'NM3T', 'PF5T', 'RSIT', 'SC1T', 'SPGT', 'TS6T', 'UM2T', 'VL1T', 'WW2T', 'ZK4T', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '13', '15', '16', '17', '18', '002', '003', '005', '006', '007', '009', '011', '012', '014', '015', '016', '017', '018', '020', '021', '023', '024', '025', '026', '029', '031', '032', '033', '034', '035', '037', '038', '039', '040', '041', '042', '01', '02', '03', '04', '05', '06', '07', '09', '10', '11', '12', '13', '14', '15', '10159', '10171', '10206', '10217', '10228', '10235', '10249', '10273', '10274', '10280', '10290', '10292', '10304', '10316', '10321', '10325', '10329', '10339', '10340', '10345', '10347', '10356', '10361', '10365', '10388', '10429', '10438', '10440', '10448', '10455', '10460', '10471', '10478', '10487', '10492', '10506', '10517', '10523', '10524', '10525', '10557', '10565', '10570', '10575', '10624', '10629', '10631', '10638', '10668', '10674', '10680', '10686', '10692', '10697', '10704', '10707', '10708', '10719', '10724', '10746', '10762', '10779', '10785', '10788', '10844', '10871', '10882', '10891', '10893', '10934', '10940', '10958', '10963', '10968', '10975', '10977', '10987', '11019', '11030', '11044', '11059', '11061', '11066', '11067', '11068', '11077', '11088', '11090', '11097', '11098', '11104', '11108', '11128', '11131', '11143', '11149', '11156']\n",
      "work_dir : /home/scotti/projects/3t_7t_sst_comparison/processing/nipype_workflow_folders/all_datasets_roi\n",
      "slm folder : /home/scotti/projects/3t_7t_sst_comparison/derivatives/glm_feat_sst_roi/subject_level_model\n",
      "output dir : /home/scotti/projects/3t_7t_sst_comparison/derivatives/glm_feat_sst_roi/group_level_model/all_datasets/model-0\n",
      "contrasts : ['0', '1', '2', '3', '4', '5']\n",
      "\n",
      "## if uneven number of template / designs / subs the code will crash\n",
      "no.copes = 174\n",
      "no.varvopes = 174\n",
      "no.tdofs = 174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "datasets : {dataset_ids}\n",
    "model_n : {model_ns}\n",
    "no. subs : {len(subject_ids)}\n",
    "subs : {subject_ids}\n",
    "work_dir : {work_dir}\n",
    "slm folder : {slm_folder}\n",
    "output dir : {output_dir}\n",
    "contrasts : {contrasts}\n",
    "\n",
    "## if uneven number of template / designs / subs the code will crash\n",
    "no.copes = {len(glob.glob(templates['level2_cope'].format(dataset_id='*',subject_id='*',model_n=model_ns[0],contrast_n=0)))}\n",
    "no.varvopes = {len(glob.glob(templates['level2_varcope'].format(dataset_id='*',subject_id='*',model_n=model_ns[0],contrast_n=0)))}\n",
    "no.tdofs = {len(glob.glob(templates['level2_tdof'].format(dataset_id='*',subject_id='*',model_n=model_ns[0],contrast_n=0)))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb50e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## make brain mask for flameo\n",
    "# import nilearn\n",
    "# from nilearn import plotting\n",
    "# import nibabel as nib\n",
    "\n",
    "# hdr = nib.load('../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii')\n",
    "# brain_data = hdr.get_fdata()\n",
    "# brain_data[brain_data>0] = 1\n",
    "# brain_mask = nib.Nifti1Image(brain_data, affine=hdr.affine, header=hdr.header)\n",
    "# brain_mask.to_filename('../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d6378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "workflow = pe.Workflow(name='feat_level3_sst_roi_alldatasets')\n",
    "workflow.base_dir = work_dir\n",
    "workflow.config = {\"execution\": {\"crashdump_dir\":os.path.join(project_folder, 'processing', 'crashdumps')}}\n",
    "\n",
    "# Identity\n",
    "identity = pe.Node(util.IdentityInterface(fields=['contrast_n', 'model_n']), name='identity') # , 'fwhm'\n",
    "identity.iterables = [('contrast_n', contrasts),\n",
    "#                       ('fwhm', fwhms),\n",
    "                      ('model_n', model_ns)]\n",
    "\n",
    "# Selector\n",
    "selector = pe.Node(nio.SelectFiles(templates), name='selector')\n",
    "workflow.connect(identity, 'contrast_n', selector, 'contrast_n')\n",
    "# workflow.connect(identity, 'fwhm', selector, 'fwhm')\n",
    "workflow.connect(identity, 'model_n', selector, 'model_n')\n",
    "\n",
    "## Merge copes, varcopes, masks\n",
    "copemerge = pe.Node(interface=fsl.Merge(dimension='t'),\n",
    "                          name=\"copemerge\")\n",
    "\n",
    "varcopemerge = pe.Node(interface=fsl.Merge(dimension='t'),\n",
    "                       name=\"varcopemerge\")\n",
    "\n",
    "workflow.connect(selector, 'level2_cope', copemerge, 'in_files')\n",
    "workflow.connect(selector, 'level2_varcope', varcopemerge, 'in_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee0109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset + subject ids\n",
    "def get_subject_ids():\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    dataset_ids, subject_ids = zip(*[(x.split('/')[-2],x.split('/')[-1].split('-')[-1]) for x in sorted(glob.glob(os.path.join('/home/scotti/projects/3t_7t_sst_comparison', \n",
    "                             'derivatives', 'glm_feat_sst_roi', 'subject_level_model', '*', 'sub-*')))])\n",
    "    return dataset_ids, subject_ids\n",
    "\n",
    "# define node to output subjects\n",
    "subject_id_getter = pe.Node(util.Function(output_names=['dataset_ids','subject_ids'],\n",
    "                                          function=get_subject_ids),\n",
    "                                          name='subject_id_getter')\n",
    "\n",
    "# create design matrix witih dummy variables for the different datasets (experimental)\n",
    "def get_design_matrix(second_level_contrast, dataset_ids, subject_ids): #=subject_ids):\n",
    "    print(second_level_contrast)\n",
    "    \n",
    "    import numpy as np\n",
    "    from patsy.contrasts import ContrastMatrix\n",
    "    from collections import Counter\n",
    "    \n",
    "#     # code to generate correct simple dummy variables\n",
    "#     def _name_levels(prefix, levels):\n",
    "#         return [\"[%s%s]\" % (prefix, level) for level in levels]\n",
    "\n",
    "#     class Simple(object):\n",
    "#         def _simple_contrast(self, levels):\n",
    "#             nlevels = len(levels)\n",
    "#             contr = -1.0 / nlevels * np.ones((nlevels, nlevels - 1))\n",
    "#             contr[1:][np.diag_indices(nlevels - 1)] = (nlevels - 1.0) / nlevels\n",
    "#             return contr\n",
    "\n",
    "#         def code_with_intercept(self, levels):\n",
    "#             contrast = np.column_stack(\n",
    "#                 (np.ones(len(levels)), self._simple_contrast(levels))\n",
    "#             )\n",
    "#             return ContrastMatrix(contrast, _name_levels(\"Simp.\", levels))\n",
    "\n",
    "#         def code_without_intercept(self, levels):\n",
    "#             contrast = self._simple_contrast(levels)\n",
    "#             return ContrastMatrix(contrast, _name_levels(\"Simp.\", levels[:-1]))\n",
    "        \n",
    "    levels = [1,2,3,4,5]\n",
    "#     contrast = Simple().code_without_intercept(levels)\n",
    "    \n",
    "#     dummies = [[-1,-1,-1,-1],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "    dummies = [[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]\n",
    "    \n",
    "    # for regressors do intercept and dummy variables\n",
    "    regressors = {#'intercept': [1 for x in range(len(subject_ids))],\n",
    "                  'GdH': list(np.repeat([item[0] for item in dummies],list(Counter(dataset_ids).values()))),\n",
    "                  'SM': list(np.repeat([item[1] for item in dummies],list(Counter(dataset_ids).values()))),\n",
    "                  'SJSI': list(np.repeat([item[2] for item in dummies],list(Counter(dataset_ids).values()))),\n",
    "                  'aron': list(np.repeat([item[3] for item in dummies],list(Counter(dataset_ids).values()))),\n",
    "                  'openfmri': list(np.repeat([item[4] for item in dummies],list(Counter(dataset_ids).values())))}\n",
    "    \n",
    "    # contrasts (3rd-level), original way, this way calculates difference of each group and mean.\n",
    "#     third_level_contrasts = [('Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [1.0, 0, 0, 0, 0]),\n",
    "#                              ('-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 0, 0, 0, 0]),\n",
    "#                              ('SM-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 1.0, 0, 0, 0]),\n",
    "#                              ('SJSI-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 0, 1.0, 0, 0]),\n",
    "#                              ('aron-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 0, 0, 1.0, 0]),\n",
    "#                              ('openfmri-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 0, 0, 0, 1.0])\n",
    "#                             ]\n",
    "    \n",
    "    # new method to calculate exact means so do not have to reconstruct later\n",
    "    third_level_contrasts = [('Group mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [1.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "                             ('-Group mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, -1.0, -1.0, -1.0, -1.0]),\n",
    "                             ('GdH mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [1.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "                             ('SM mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [0.0, 1.0, 0, 0, 0]),\n",
    "                             ('SJSI mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [0.0, 0, 1.0, 0, 0]),\n",
    "                             ('aron mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [0.0, 0, 0, 1.0, 0]),\n",
    "                             ('openfmri mean', 'T', ['GdH', 'SM', 'SJSI', 'aron', 'openfmri'], [0.0, 0, 0, 0, 1.0])\n",
    "                            ]\n",
    "\n",
    "# Unsure which third level contrasts to use ?? fix\n",
    "#     third_level_contrasts = [('Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [1.0, 0, 0, 0, 0]),\n",
    "#                              ('-Group mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [-1.0, 0, 0, 0, 0]),\n",
    "#                              ('SM mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 1.0, 0, 0, 0]),\n",
    "#                              ('-SM mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, -1.0, 0, 0, 0]),\n",
    "#                              ('SJSI mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, 1.0, 0, 0]),\n",
    "#                              ('-SJSI mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, -1.0, 0, 0]),\n",
    "#                              ('aron mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, 0, 1.0, 0]),\n",
    "#                              ('-aron mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, 0, -1.0, 0]),\n",
    "#                              ('openfmri mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, 0, 0, 1.0]),\n",
    "#                              ('-openfmri mean', 'T', ['intercept', 'SM', 'SJSI', 'aron', 'openfmri'], [0, 0, 0, 0, -1.0]),\n",
    "#                              ]\n",
    "    \n",
    "    # fix this so can use different vairrance group: issue is that design matrix is not separable\n",
    "    groups = list(np.repeat(levels, list(Counter(dataset_ids).values()))) # set different dataset as groups to estimate variance separately\n",
    "#     groups = [1 for x in range(len(subject_ids))]\n",
    "    \n",
    "    return third_level_contrasts, regressors, groups\n",
    "\n",
    "contrastgen_l3 = pe.Node(util.Function(input_names=['second_level_contrast', 'dataset_ids', 'subject_ids'],\n",
    "                                       output_names=['third_level_contrasts', 'regressors', 'groups'],\n",
    "                                       function=get_design_matrix),\n",
    "                      name='contrastgen_l3')\n",
    "\n",
    "level3model = pe.Node(interface=fsl.MultipleRegressDesign(),\n",
    "                      name='l3model')\n",
    "\n",
    "workflow.connect(subject_id_getter, 'dataset_ids', contrastgen_l3, 'dataset_ids')\n",
    "workflow.connect(subject_id_getter, 'subject_ids', contrastgen_l3, 'subject_ids')\n",
    "workflow.connect(identity, 'contrast_n', contrastgen_l3, 'second_level_contrast')\n",
    "workflow.connect(contrastgen_l3, 'third_level_contrasts', level3model, 'contrasts')\n",
    "workflow.connect(contrastgen_l3, 'regressors', level3model, 'regressors')\n",
    "workflow.connect(contrastgen_l3, 'groups', level3model, 'groups')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1add8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run flame 1 + 2\n",
    "flameo = pe.Node(\n",
    "    interface=fsl.FLAMEO(),\n",
    "    name=\"flameo\")\n",
    "\n",
    "flameo.iterables = ('run_mode', ['ols', 'flame1', 'flame12'])\n",
    "flameo.inputs.mask_file = template_brain_mask\n",
    "flameo.inputs.infer_outliers = False   # run with automatic outlier detection\n",
    "\n",
    "workflow.connect([\n",
    "    (copemerge, flameo, [('merged_file', 'cope_file')]),\n",
    "    (varcopemerge, flameo, [('merged_file', 'var_cope_file')]),\n",
    "    (level3model, flameo, [('design_mat', 'design_file'),\n",
    "                           ('design_con', 't_con_file'), \n",
    "                           ('design_grp', 'cov_split_file')]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "767b3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## cluster thresholding\n",
    "# # Smoothness estimation\n",
    "# smoothestimate = pe.MapNode(fsl.SmoothEstimate(), iterfield=['zstat_file'], name='smoothestimate')\n",
    "# smoothestimate.inputs.mask_file = template_brain_mask\n",
    "\n",
    "# workflow.connect(flameo, 'zstats', smoothestimate, 'zstat_file')\n",
    "\n",
    "# # get volume\n",
    "# get_volume = pe.Node(fsl.ImageStats(op_string = '-V'), name='get_volume')\n",
    "# get_volume.inputs.in_file = template_brain_mask\n",
    "\n",
    "# # Cluster threshold\n",
    "# grf_cluster = pe.MapNode(fsl.Cluster(), iterfield=['dlh', 'in_file'], name='grf_cluster')\n",
    "# grf_cluster.iterables = [(\"threshold\", [2.3, 3.1])]\n",
    "# grf_cluster.inputs.out_localmax_txt_file = True\n",
    "# grf_cluster.inputs.pthreshold = 0.05\n",
    "# grf_cluster.inputs.out_index_file = True\n",
    "# grf_cluster.inputs.out_threshold_file = True\n",
    "\n",
    "# def volume_convert(input):\n",
    "#     return int(input[0])\n",
    "\n",
    "# workflow.connect(get_volume, ('out_stat', volume_convert), grf_cluster, 'volume')\n",
    "# workflow.connect(smoothestimate, 'dlh', grf_cluster, 'dlh')\n",
    "# workflow.connect(flameo, 'zstats', grf_cluster, 'in_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c45f089",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grf_cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m workflow\u001b[38;5;241m.\u001b[39mconnect(flameo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtdof\u001b[39m\u001b[38;5;124m'\u001b[39m, datasink, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_level_model.level3_tdof_ts\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m## cluster results\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m workflow\u001b[38;5;241m.\u001b[39mconnect(\u001b[43mgrf_cluster\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold_file\u001b[39m\u001b[38;5;124m'\u001b[39m, datasink, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_level_model.grf_thresholded_zstats_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m workflow\u001b[38;5;241m.\u001b[39mconnect(grf_cluster, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalmax_txt_file\u001b[39m\u001b[38;5;124m'\u001b[39m, datasink, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_level_model.grf_localmax_txt_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m workflow\u001b[38;5;241m.\u001b[39mconnect(grf_cluster, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_file\u001b[39m\u001b[38;5;124m'\u001b[39m, datasink, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_level_model.grf_cluster_indices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grf_cluster' is not defined"
     ]
    }
   ],
   "source": [
    "## Datasink, how to output the data\n",
    "datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "datasink.inputs.base_directory=output_dir\n",
    "\n",
    "# rename some files so they're not split over a bunch of folders\n",
    "# depending on the FWHM used, the regexp might have to be adpated due to number of elements\n",
    "substitutions_regexp = [(r'third_level_model/grf_thresholded_zstats_file/_contrast_n_(\\d+)_model_n_(\\S+)/_run_mode_flame(\\S+)/_threshold_(\\S+)/_grf_cluster(\\d)/(\\S+)(\\d)_threshold.nii.gz',\n",
    "                         'model-\\\\2/model-\\\\2_subjectlevelcontrast-\\\\1_grouplevelcontrast-\\\\7_flame-\\\\3_desc-\\\\6_voxelthreshold-\\\\4.nii.gz'),\n",
    "                        (r'third_level_model/level3_.*/_contrast_n_(\\d+)_model_n_(\\S+)/_run_mode_flame(\\S+)/(\\S+)(\\d).nii.gz',\n",
    "                          'model-\\\\2/model-\\\\2_subjectlevelcontrast-\\\\1_grouplevelcontrast-\\\\5_flame-\\\\3_desc-\\\\4.nii.gz'),\n",
    "                        (r'third_level_model/level3_.*/_contrast_n_(\\d+)_model_n_(\\S+)/_run_mode_ols/(\\S+)(\\d).nii.gz',\n",
    "                          'model-\\\\2/model-\\\\2_subjectlevelcontrast-\\\\1_grouplevelcontrast-\\\\4_flame-ols_desc-\\\\3.nii.gz'),\n",
    "                        # (r'third_level_model/grf_localmax_.*/fwhm-(\\S{3})/model-(\\S+)/contrast-(\\d+)/_run_mode_flame(\\d+)/_threshold_(\\S+)/_grf_cluster(\\d)/zstat1_(\\S+).txt',\n",
    "                        #   'model-\\\\2/model-\\\\2_fwhm-\\\\1_subjectlevelcontrast-\\\\3_grouplevelcontrast-\\\\6_flame-\\\\4_desc-zstat_\\\\7-voxelthreshold-\\\\5.txt')\n",
    "                       ]\n",
    "\n",
    "datasink.inputs.regexp_substitutions = substitutions_regexp\n",
    "\n",
    "## todo: substitutions\n",
    "workflow.connect(flameo, 'zstats', datasink, 'third_level_model.level3_zstats')\n",
    "workflow.connect(flameo, 'copes', datasink, 'third_level_model.level3_copes')\n",
    "workflow.connect(flameo, 'var_copes', datasink, 'third_level_model.level3_varcopes')\n",
    "workflow.connect(flameo, 'tdof', datasink, 'third_level_model.level3_tdof_ts')\n",
    "\n",
    "## cluster results\n",
    "workflow.connect(grf_cluster, 'threshold_file', datasink, 'third_level_model.grf_thresholded_zstats_file')\n",
    "workflow.connect(grf_cluster, 'localmax_txt_file', datasink, 'third_level_model.grf_localmax_txt_file')\n",
    "workflow.connect(grf_cluster, 'index_file', datasink, 'third_level_model.grf_cluster_indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa68713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow.run(plugin='MultiProc', plugin_args={'n_procs': 24, 'memory_gb': 240})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a193a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
